{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup",
   "id": "6d72fc54c63f6f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T11:44:06.659780Z",
     "start_time": "2024-06-12T11:43:57.181929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -U langchain langchain-community tavily-python faiss-cpu huggingface_hub langgraph langchain_experimental"
   ],
   "id": "c9d5e21ad6362463",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.12/site-packages (24.0)\r\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.12/site-packages (0.2.3)\r\n",
      "Requirement already satisfied: langchain-community in ./.venv/lib/python3.12/site-packages (0.2.4)\r\n",
      "Requirement already satisfied: tavily-python in ./.venv/lib/python3.12/site-packages (0.3.3)\r\n",
      "Requirement already satisfied: faiss-cpu in ./.venv/lib/python3.12/site-packages (1.8.0)\r\n",
      "Requirement already satisfied: huggingface_hub in ./.venv/lib/python3.12/site-packages (0.23.3)\r\n",
      "Requirement already satisfied: langgraph in ./.venv/lib/python3.12/site-packages (0.0.66)\r\n",
      "Requirement already satisfied: langchain_experimental in ./.venv/lib/python3.12/site-packages (0.0.60)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain) (2.0.30)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.12/site-packages (from langchain) (3.9.5)\r\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in ./.venv/lib/python3.12/site-packages (from langchain) (0.2.5)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.venv/lib/python3.12/site-packages (from langchain) (0.2.1)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.venv/lib/python3.12/site-packages (from langchain) (0.1.77)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.12/site-packages (from langchain) (1.26.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.12/site-packages (from langchain) (2.7.3)\r\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.12/site-packages (from langchain) (2.32.3)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain) (8.3.0)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.12/site-packages (from langchain-community) (0.6.7)\r\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in ./.venv/lib/python3.12/site-packages (from tavily-python) (0.7.0)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface_hub) (3.14.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface_hub) (2024.6.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.12/site-packages (from huggingface_hub) (23.2)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.12/site-packages (from huggingface_hub) (4.66.4)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface_hub) (4.12.2)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.6.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.5.2->tavily-python) (2024.5.15)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (3.0.0)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup Tavily",
   "id": "e493a4c2e6b1abfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T16:32:02.090141Z",
     "start_time": "2024-06-12T16:32:02.086473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"MY API KEY\"\n",
    "\n",
    "search = TavilySearchResults(max_results=2)"
   ],
   "id": "595b6adef6fc458f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Non-working example\n",
    "\n",
    "The changes I had to make to the code was:\n",
    "\n",
    "ollama_functions.py\n",
    "```python\n",
    "\n",
    "# Update to the default system template adding in two additional lines. I found that llama3 was not always respecting the schema of the tools.\n",
    "DEFAULT_SYSTEM_TEMPLATE = \"\"\"You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "You must always select one of the above tools and respond with only a JSON object matching the following schema:\n",
    "\n",
    "{{\n",
    "  \"tool\": <name of the selected tool>,\n",
    "  \"tool_input\": <parameters for the selected tool, matching the tool's JSON schema>\n",
    "}}\n",
    "\n",
    "Double check that in your json, you only have `tool` and `tool_input`.\n",
    "Also Double check that the tool_input is an object and matches the parameters for the selected tool, matching the tool's JSON schema.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "# Update to the _generate message\n",
    "I had to remove the if check in the _generate function as the check for if it was a is_pydantic_class always failed\n",
    "```python\n",
    "    # if _is_pydantic_class(functions[0]):\n",
    "    functions = [convert_to_ollama_tool(fn) for fn in functions]\n",
    "    functions.insert(0, DEFAULT_RESPONSE_FUNCTION)\n",
    "```\n",
    "\n",
    "# update the ollama tool conversion function\n",
    "def convert_to_ollama_tool(tool: Any) -> Dict:\n",
    "    \"\"\"Convert a tool to an Ollama tool.\"\"\"\n",
    "\n",
    "    if _is_pydantic_class(tool.__class__):\n",
    "        schema = tool.__dict__[\"args_schema\"].schema()\n",
    "        definition = {\"name\": tool.name, \"properties\": schema[\"properties\"]}\n",
    "        if \"required\" in schema:\n",
    "            definition[\"required\"] = schema[\"required\"]\n",
    "\n",
    "        return definition\n",
    "    raise ValueError(\n",
    "        f\"Cannot convert {tool} to an Ollama tool. {tool} needs to be a Pydantic model.\"\n",
    "    )\n",
    "```\n",
    "\n",
    "chat_models/ollama.py\n",
    "```python\n",
    "def _convert_messages_to_ollama_messages(\n",
    "        self, messages: List[BaseMessage]\n",
    "    ) -> List[Dict[str, Union[str, List[str]]]]:\n",
    "        ollama_messages: List = []\n",
    "        for message in messages:\n",
    "            role = \"\"\n",
    "            if isinstance(message, HumanMessage):\n",
    "                role = \"user\"\n",
    "            elif isinstance(message, AIMessage):\n",
    "                role = \"assistant\"\n",
    "            elif isinstance(message, SystemMessage):\n",
    "                role = \"system\"\n",
    "            elif isinstance(message, ToolMessage): # Added this line, needed to add this to the list of supported message types\n",
    "                role = \"user\"\n",
    "            else:\n",
    "                raise ValueError(\"Received unsupported message type for Ollama.\")\n",
    "\n",
    "            content = \"\"\n",
    "```\n"
   ],
   "id": "44a234803eb6b687"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-12T18:57:38.058382Z",
     "start_time": "2024-06-12T18:57:37.431557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = OllamaFunctions(model=\"mistral\", format=\"json\")\n",
    "\n",
    "tools=[search]\n",
    "            \n",
    "agent_executor = create_react_agent(llm, tools=tools)\n",
    "\n",
    "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"What is the weather in London?\")]})\n",
    "\n",
    "response[\"messages\"]\n",
    "\n"
   ],
   "id": "1570ddcbb6c8fda",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type TavilySearchResults is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 11\u001B[0m\n\u001B[1;32m      7\u001B[0m tools\u001B[38;5;241m=\u001B[39m[search]\n\u001B[1;32m      9\u001B[0m agent_executor \u001B[38;5;241m=\u001B[39m create_react_agent(llm, tools\u001B[38;5;241m=\u001B[39mtools)\n\u001B[0;32m---> 11\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43magent_executor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmessages\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mHumanMessage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mWhat is the weather in London?\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1400\u001B[0m, in \u001B[0;36mPregel.invoke\u001B[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001B[0m\n\u001B[1;32m   1398\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1399\u001B[0m     chunks \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m-> 1400\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1401\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1402\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1403\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1404\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1405\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1406\u001B[0m \u001B[43m    \u001B[49m\u001B[43minterrupt_before\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterrupt_before\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1407\u001B[0m \u001B[43m    \u001B[49m\u001B[43minterrupt_after\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterrupt_after\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdebug\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1409\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1410\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1411\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstream_mode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvalues\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1412\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlatest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:963\u001B[0m, in \u001B[0;36mPregel.stream\u001B[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001B[0m\n\u001B[1;32m    960\u001B[0m         \u001B[38;5;28;01mdel\u001B[39;00m fut, task\n\u001B[1;32m    962\u001B[0m \u001B[38;5;66;03m# panic on failure or timeout\u001B[39;00m\n\u001B[0;32m--> 963\u001B[0m \u001B[43m_panic_or_proceed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdone\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minflight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    964\u001B[0m \u001B[38;5;66;03m# don't keep futures around in memory longer than needed\u001B[39;00m\n\u001B[1;32m    965\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m done, inflight, futures\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1489\u001B[0m, in \u001B[0;36m_panic_or_proceed\u001B[0;34m(done, inflight, step)\u001B[0m\n\u001B[1;32m   1487\u001B[0m             inflight\u001B[38;5;241m.\u001B[39mpop()\u001B[38;5;241m.\u001B[39mcancel()\n\u001B[1;32m   1488\u001B[0m         \u001B[38;5;66;03m# raise the exception\u001B[39;00m\n\u001B[0;32m-> 1489\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[1;32m   1491\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inflight:\n\u001B[1;32m   1492\u001B[0m     \u001B[38;5;66;03m# if we got here means we timed out\u001B[39;00m\n\u001B[1;32m   1493\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m inflight:\n\u001B[1;32m   1494\u001B[0m         \u001B[38;5;66;03m# cancel all pending tasks\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/thread.py:58\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langgraph/pregel/retry.py:66\u001B[0m, in \u001B[0;36mrun_with_retry\u001B[0;34m(task, retry_policy)\u001B[0m\n\u001B[1;32m     64\u001B[0m task\u001B[38;5;241m.\u001B[39mwrites\u001B[38;5;241m.\u001B[39mclear()\n\u001B[1;32m     65\u001B[0m \u001B[38;5;66;03m# run the task\u001B[39;00m\n\u001B[0;32m---> 66\u001B[0m \u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;66;03m# if successful, end\u001B[39;00m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:2493\u001B[0m, in \u001B[0;36mRunnableSequence.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   2489\u001B[0m config \u001B[38;5;241m=\u001B[39m patch_config(\n\u001B[1;32m   2490\u001B[0m     config, callbacks\u001B[38;5;241m=\u001B[39mrun_manager\u001B[38;5;241m.\u001B[39mget_child(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseq:step:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   2491\u001B[0m )\n\u001B[1;32m   2492\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 2493\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mstep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2494\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   2495\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m step\u001B[38;5;241m.\u001B[39minvoke(\u001B[38;5;28minput\u001B[39m, config)\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3961\u001B[0m, in \u001B[0;36mRunnableLambda.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   3959\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Invoke this runnable synchronously.\"\"\"\u001B[39;00m\n\u001B[1;32m   3960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfunc\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 3961\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_with_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3962\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_invoke\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3963\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3964\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3965\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3966\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3967\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3968\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m   3969\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot invoke a coroutine function synchronously.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3970\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUse `ainvoke` instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3971\u001B[0m     )\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:1596\u001B[0m, in \u001B[0;36mRunnable._call_with_config\u001B[0;34m(self, func, input, config, run_type, **kwargs)\u001B[0m\n\u001B[1;32m   1592\u001B[0m     context \u001B[38;5;241m=\u001B[39m copy_context()\n\u001B[1;32m   1593\u001B[0m     context\u001B[38;5;241m.\u001B[39mrun(_set_config_context, child_config)\n\u001B[1;32m   1594\u001B[0m     output \u001B[38;5;241m=\u001B[39m cast(\n\u001B[1;32m   1595\u001B[0m         Output,\n\u001B[0;32m-> 1596\u001B[0m         \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1597\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1598\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1599\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m   1600\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1601\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1602\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1603\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m   1604\u001B[0m     )\n\u001B[1;32m   1605\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1606\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:380\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[0;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[1;32m    379\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[0;32m--> 380\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3835\u001B[0m, in \u001B[0;36mRunnableLambda._invoke\u001B[0;34m(self, input, run_manager, config, **kwargs)\u001B[0m\n\u001B[1;32m   3833\u001B[0m                 output \u001B[38;5;241m=\u001B[39m chunk\n\u001B[1;32m   3834\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 3835\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3836\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m   3837\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3838\u001B[0m \u001B[38;5;66;03m# If the output is a runnable, invoke it\u001B[39;00m\n\u001B[1;32m   3839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output, Runnable):\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langchain_core/runnables/config.py:380\u001B[0m, in \u001B[0;36mcall_func_with_variable_args\u001B[0;34m(func, input, config, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m run_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m accepts_run_manager(func):\n\u001B[1;32m    379\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m run_manager\n\u001B[0;32m--> 380\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langgraph/prebuilt/chat_agent_executor.py:403\u001B[0m, in \u001B[0;36mcreate_react_agent.<locals>.call_model\u001B[0;34m(state, config)\u001B[0m\n\u001B[1;32m    398\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_model\u001B[39m(\n\u001B[1;32m    399\u001B[0m     state: AgentState,\n\u001B[1;32m    400\u001B[0m     config: RunnableConfig,\n\u001B[1;32m    401\u001B[0m ):\n\u001B[1;32m    402\u001B[0m     messages \u001B[38;5;241m=\u001B[39m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m--> 403\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_runnable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    404\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis_last_step\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;129;01mand\u001B[39;00m response\u001B[38;5;241m.\u001B[39mtool_calls:\n\u001B[1;32m    405\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m    406\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessages\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[1;32m    407\u001B[0m                 AIMessage(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    411\u001B[0m             ]\n\u001B[1;32m    412\u001B[0m         }\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:4558\u001B[0m, in \u001B[0;36mRunnableBindingBase.invoke\u001B[0;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[1;32m   4552\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m   4553\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4554\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[1;32m   4555\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   4556\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[1;32m   4557\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Output:\n\u001B[0;32m-> 4558\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbound\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4559\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4560\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_merge_configs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4561\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4562\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:170\u001B[0m, in \u001B[0;36mBaseChatModel.invoke\u001B[0;34m(self, input, config, stop, **kwargs)\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;28minput\u001B[39m: LanguageModelInput,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    166\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[1;32m    167\u001B[0m     config \u001B[38;5;241m=\u001B[39m ensure_config(config)\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[1;32m    169\u001B[0m         ChatGeneration,\n\u001B[0;32m--> 170\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcallbacks\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtags\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrun_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m],\n\u001B[1;32m    180\u001B[0m     )\u001B[38;5;241m.\u001B[39mmessage\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:599\u001B[0m, in \u001B[0;36mBaseChatModel.generate_prompt\u001B[0;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[1;32m    592\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    593\u001B[0m     prompts: List[PromptValue],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    596\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    597\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[1;32m    598\u001B[0m     prompt_messages \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[0;32m--> 599\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:456\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    454\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n\u001B[1;32m    455\u001B[0m             run_managers[i]\u001B[38;5;241m.\u001B[39mon_llm_error(e, response\u001B[38;5;241m=\u001B[39mLLMResult(generations\u001B[38;5;241m=\u001B[39m[]))\n\u001B[0;32m--> 456\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    457\u001B[0m flattened_outputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    458\u001B[0m     LLMResult(generations\u001B[38;5;241m=\u001B[39m[res\u001B[38;5;241m.\u001B[39mgenerations], llm_output\u001B[38;5;241m=\u001B[39mres\u001B[38;5;241m.\u001B[39mllm_output)  \u001B[38;5;66;03m# type: ignore[list-item]\u001B[39;00m\n\u001B[1;32m    459\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results\n\u001B[1;32m    460\u001B[0m ]\n\u001B[1;32m    461\u001B[0m llm_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_combine_llm_outputs([res\u001B[38;5;241m.\u001B[39mllm_output \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results])\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:446\u001B[0m, in \u001B[0;36mBaseChatModel.generate\u001B[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(messages):\n\u001B[1;32m    444\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    445\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m--> 446\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    447\u001B[0m \u001B[43m                \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    448\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    449\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    451\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    452\u001B[0m         )\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    454\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m run_managers:\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:671\u001B[0m, in \u001B[0;36mBaseChatModel._generate_with_cache\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    670\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 671\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    674\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    675\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(messages, stop\u001B[38;5;241m=\u001B[39mstop, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/Coding/Python/llm-playground/second-trial/.venv/lib/python3.12/site-packages/langchain_experimental/llms/ollama_functions.py:307\u001B[0m, in \u001B[0;36mOllamaFunctions._generate\u001B[0;34m(self, messages, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    302\u001B[0m functions\u001B[38;5;241m.\u001B[39minsert(\u001B[38;5;241m0\u001B[39m, DEFAULT_RESPONSE_FUNCTION)\n\u001B[1;32m    303\u001B[0m system_message_prompt_template \u001B[38;5;241m=\u001B[39m SystemMessagePromptTemplate\u001B[38;5;241m.\u001B[39mfrom_template(\n\u001B[1;32m    304\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtool_system_prompt_template\n\u001B[1;32m    305\u001B[0m )\n\u001B[1;32m    306\u001B[0m system_message \u001B[38;5;241m=\u001B[39m system_message_prompt_template\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m--> 307\u001B[0m     tools\u001B[38;5;241m=\u001B[39m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdumps\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunctions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    308\u001B[0m )\n\u001B[1;32m    309\u001B[0m response_message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m_generate(\n\u001B[1;32m    310\u001B[0m     [system_message] \u001B[38;5;241m+\u001B[39m messages, stop\u001B[38;5;241m=\u001B[39mstop, run_manager\u001B[38;5;241m=\u001B[39mrun_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    311\u001B[0m )\n\u001B[1;32m    312\u001B[0m chat_generation_content \u001B[38;5;241m=\u001B[39m response_message\u001B[38;5;241m.\u001B[39mgenerations[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mtext\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/__init__.py:238\u001B[0m, in \u001B[0;36mdumps\u001B[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m JSONEncoder\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[43m    \u001B[49m\u001B[43mskipkeys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipkeys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_ascii\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_ascii\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    236\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheck_circular\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_circular\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nan\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    237\u001B[0m \u001B[43m    \u001B[49m\u001B[43mseparators\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseparators\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefault\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msort_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m--> 238\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:202\u001B[0m, in \u001B[0;36mJSONEncoder.encode\u001B[0;34m(self, o)\u001B[0m\n\u001B[1;32m    200\u001B[0m chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miterencode(o, _one_shot\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    201\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(chunks, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[0;32m--> 202\u001B[0m     chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mchunks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(chunks)\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:430\u001B[0m, in \u001B[0;36m_make_iterencode.<locals>._iterencode\u001B[0;34m(o, _current_indent_level)\u001B[0m\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m _floatstr(o)\n\u001B[1;32m    429\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(o, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[0;32m--> 430\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _iterencode_list(o, _current_indent_level)\n\u001B[1;32m    431\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(o, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    432\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:326\u001B[0m, in \u001B[0;36m_make_iterencode.<locals>._iterencode_list\u001B[0;34m(lst, _current_indent_level)\u001B[0m\n\u001B[1;32m    324\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    325\u001B[0m             chunks \u001B[38;5;241m=\u001B[39m _iterencode(value, _current_indent_level)\n\u001B[0;32m--> 326\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m chunks\n\u001B[1;32m    327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m newline_indent \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    328\u001B[0m     _current_indent_level \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:439\u001B[0m, in \u001B[0;36m_make_iterencode.<locals>._iterencode\u001B[0;34m(o, _current_indent_level)\u001B[0m\n\u001B[1;32m    437\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCircular reference detected\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    438\u001B[0m     markers[markerid] \u001B[38;5;241m=\u001B[39m o\n\u001B[0;32m--> 439\u001B[0m o \u001B[38;5;241m=\u001B[39m \u001B[43m_default\u001B[49m\u001B[43m(\u001B[49m\u001B[43mo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m _iterencode(o, _current_indent_level)\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m markers \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/json/encoder.py:180\u001B[0m, in \u001B[0;36mJSONEncoder.default\u001B[0;34m(self, o)\u001B[0m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault\u001B[39m(\u001B[38;5;28mself\u001B[39m, o):\n\u001B[1;32m    162\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001B[39;00m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001B[39;00m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;124;03m    (to raise a ``TypeError``).\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    178\u001B[0m \n\u001B[1;32m    179\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 180\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mObject of type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mo\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    181\u001B[0m                     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mis not JSON serializable\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: Object of type TavilySearchResults is not JSON serializable"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
